{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b8d962f-1780-421a-b3fe-63cc9a07c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, sum as spark_sum, expr, datediff, when, first, max as spark_max\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DateType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DWH Population\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/home/jovyan/postgresql-42.7.4.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"mysecretpassword\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5fed23c-4279-4951-a037-c26bdc6366ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = spark.read.jdbc(url=jdbc_url, table=\"dwh.d_customers\", properties=properties)\n",
    "products_df = spark.read.jdbc(url=jdbc_url, table=\"dwh.d_products\", properties=properties)\n",
    "craftsmans_df = spark.read.jdbc(url=jdbc_url, table=\"dwh.d_craftsmans\", properties=properties)\n",
    "orders_df = spark.read.jdbc(url=jdbc_url, table=\"dwh.f_orders\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7160869c-19b9-4aba-b91d-131bf915b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_load_date_df = spark.read.jdbc(url=jdbc_url, table=\"dwh.load_dates_craftsman_report_datamart\", properties=properties)\n",
    "\n",
    "last_load_date = last_load_date_df.agg(spark_max(\"load_dttm\")).collect()[0][0]\n",
    "if last_load_date is None:\n",
    "    filtered_customers_df = customers_df\n",
    "    filtered_products_df = products_df\n",
    "    filtered_craftsmans_df = craftsmans_df\n",
    "    filtered_orders_df = orders_df\n",
    "else:\n",
    "    filtered_customers_df = customers_df.filter(col(\"load_dttm\") > last_load_date)\n",
    "    filtered_products_df = products_df.filter(col(\"load_dttm\") > last_load_date)\n",
    "    filtered_craftsmans_df = craftsmans_df.filter(col(\"load_dttm\") > last_load_date)\n",
    "    filtered_orders_df = orders_df.filter(col(\"load_dttm\") > last_load_date)\n",
    "    \n",
    "joined_df = filtered_orders_df.join(filtered_products_df, \"product_id\") \\\n",
    "    .join(filtered_craftsmans_df, \"craftsman_id\") \\\n",
    "    .join(filtered_customers_df, \"customer_id\")\n",
    "\n",
    "joined_df = joined_df.withColumn(\"report_period\", F.date_format(col(\"order_created_date\"), \"yyyy-MM\"))\n",
    "\n",
    "window_spec = Window.partitionBy(\"craftsman_id\", \"report_period\").orderBy(\"order_completion_date\")\n",
    "joined_df = joined_df.withColumn(\"median_time_order_completed\",\n",
    "                                 datediff(col(\"order_completion_date\"), col(\"order_created_date\")))\n",
    "\n",
    "joined_df = joined_df.withColumn(\"customer_age\",\n",
    "                                 F.datediff(F.current_date(), col(\"customer_birthday\")) / 365.25)\n",
    "\n",
    "agg_df = joined_df.groupBy(\"craftsman_id\", \"craftsman_name\", \"craftsman_address\", \"craftsman_birthday\", \"craftsman_email\", \"report_period\") \\\n",
    "    .agg(\n",
    "        spark_sum(col(\"product_price\") * 0.9).alias(\"craftsman_money\"),\n",
    "        spark_sum(col(\"product_price\") * 0.1).alias(\"platform_money\"),\n",
    "        count(\"order_id\").alias(\"count_order\"),\n",
    "        avg(col(\"product_price\")).alias(\"avg_price_order\"),\n",
    "        avg(col(\"customer_age\")).alias(\"avg_age_customer\"),\n",
    "        expr(\"percentile_approx(median_time_order_completed, 0.5)\").alias(\"median_time_order_completed\"),\n",
    "        count(when(col(\"order_status\") == \"created\", True)).alias(\"count_order_created\"),\n",
    "        count(when(col(\"order_status\") == \"in progress\", True)).alias(\"count_order_in_progress\"),\n",
    "        count(when(col(\"order_status\") == \"delivery\", True)).alias(\"count_order_delivery\"),\n",
    "        count(when(col(\"order_status\") == \"done\", True)).alias(\"count_order_done\"),\n",
    "        count(when(col(\"order_status\").isin(\"created\", \"in progress\", \"delivery\"), True)).alias(\"count_order_not_done\")\n",
    "    )\n",
    "\n",
    "product_category_count_df = joined_df.groupBy(\"craftsman_id\", \"report_period\", \"product_type\") \\\n",
    "    .agg(count(\"product_id\").alias(\"product_count\"))\n",
    "\n",
    "window_spec_category = Window.partitionBy(\"craftsman_id\", \"report_period\").orderBy(col(\"product_count\").desc())\n",
    "top_product_category_df = product_category_count_df.withColumn(\"rank\", F.row_number().over(window_spec_category)) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .select(\"craftsman_id\", \"report_period\", \"product_type\") \\\n",
    "    .withColumnRenamed(\"product_type\", \"top_product_category\")\n",
    "\n",
    "final_df = agg_df.join(top_product_category_df, [\"craftsman_id\", \"report_period\"], \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0467b13-ae31-40e9-bb9a-2702d9f9e526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.write.jdbc(url=jdbc_url, table=\"dwh.craftsman_report_datamart\", mode=\"append\", properties=properties)\n",
    "\n",
    "current_load_date = F.current_date()\n",
    "spark.read.jdbc(url=jdbc_url, table=\"dwh.load_dates_craftsman_report_datamart\", properties=properties) \\\n",
    "    .createOrReplaceTempView(\"load_dates_craftsman_report_datamart\")\n",
    "\n",
    "max_id_df = spark.sql(\"SELECT MAX(id) AS max_id FROM load_dates_craftsman_report_datamart\")\n",
    "max_id = max_id_df.collect()[0][0]\n",
    "\n",
    "next_id = 1 if max_id is None else max_id + 1\n",
    "\n",
    "spark.sql(f\"INSERT INTO load_dates_craftsman_report_datamart (id, load_dttm) VALUES ({next_id}, CURRENT_DATE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f8b804d-bfa8-4688-9c59-12059be15c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[craftsman_id: bigint, report_period: string, craftsman_name: string, craftsman_address: string, craftsman_birthday: date, craftsman_email: string, craftsman_money: double, platform_money: double, count_order: bigint, avg_price_order: double, avg_age_customer: double, median_time_order_completed: int, count_order_created: bigint, count_order_in_progress: bigint, count_order_delivery: bigint, count_order_done: bigint, count_order_not_done: bigint, top_product_category: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddca669-d5c7-4ce0-a51f-5cf12e2d3264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
